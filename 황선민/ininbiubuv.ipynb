{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "328ff0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 행 수: 498094\n",
      "삭제된 행 수(특수문자 ≥40): 86568\n",
      "최종 행 수: 411526\n",
      "저장 완료 → weighted_score_above_08_translated_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# 입력 / 출력 경로\n",
    "input_csv = Path(\"weighted_score_above_08_translated_patched.csv\")   # 원본 파일\n",
    "output_csv = Path(\"weighted_score_above_08_translated_cleaned.csv\")  # 결과 파일\n",
    "\n",
    "# 정규식\n",
    "HEADING_TAG = re.compile(r\"\\[h[0-9]+\\]\")  # [h1], [h2], ...\n",
    "def count_specials(s: str) -> int:\n",
    "    return sum(1 for ch in s if not ch.isalnum() and not ch.isspace())\n",
    "\n",
    "total, dropped = 0, 0\n",
    "\n",
    "with open(input_csv, \"r\", encoding=\"utf-8\", newline=\"\") as f_in, \\\n",
    "     open(output_csv, \"w\", encoding=\"utf-8-sig\", newline=\"\") as f_out:\n",
    "    \n",
    "    reader = csv.DictReader(f_in)\n",
    "    fieldnames = reader.fieldnames\n",
    "    if \"translated_en\" not in fieldnames:\n",
    "        raise KeyError(\"Column 'translated_en' not found in CSV.\")\n",
    "    \n",
    "    writer = csv.DictWriter(f_out, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        total += 1\n",
    "        text = str(row.get(\"translated_en\") or \"\")\n",
    "        # 1) 특수문자 40개 이상이면 DROP\n",
    "        if count_specials(text) >= 40:\n",
    "            dropped += 1\n",
    "            continue\n",
    "        # 2) [h숫자] 토큰 제거\n",
    "        cleaned_text = HEADING_TAG.sub(\"\", text)\n",
    "        row[\"translated_en\"] = cleaned_text\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"총 행 수: {total}\")\n",
    "print(f\"삭제된 행 수(특수문자 ≥40): {dropped}\")\n",
    "print(f\"최종 행 수: {total - dropped}\")\n",
    "print(f\"저장 완료 → {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0a91995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 행 수: 411526\n",
      "영어로만 된 행: 401660\n",
      "비영문(번역 안 된 듯한) 행: 9866\n",
      "\n",
      "비영문 샘플 예시 (최대 30개):\n",
      "{'row_index': 35, 'text': 'Here I will leave the cat, friends who pass by can pet it and give it a thumbs up \\u3000\\u3000\\u3000 \\u3000\\u3000／＞\\u3000\\u3000フ \\u3000\\u3000\\u3000 \\u3000\\u3000| \\u3000_\\u3000 _ l \\u3000 \\u3000\\u3000 \\u3000／` ミ＿xノ \\u3000\\u3000 \\u3000 /\\u3000\\u3000\\u3000 \\u3000 | \\u3000\\u3000\\u3000 /\\u3000 ヽ\\u3000\\u3000 ﾉ \\u3000 \\u3000 │\\u3000\\u3000|\\u3000|\\u3000| \\u3000／￣|\\u3000\\u3000 |\\u3000|\\u3000| \\u3000| (￣ヽ＿_ヽ_)__) \\u3000＼二つ'}\n",
      "{'row_index': 50, 'text': 'Here I will leave the cat, friends who pass by can pet it and give it a thumbs up \\u3000\\u3000\\u3000 \\u3000\\u3000／＞\\u3000\\u3000フ \\u3000\\u3000\\u3000 \\u3000\\u3000| \\u3000_\\u3000 _ l \\u3000 \\u3000\\u3000 \\u3000／` ミ＿xノ \\u3000\\u3000 \\u3000 /\\u3000\\u3000\\u3000 \\u3000 | \\u3000\\u3000\\u3000 /\\u3000 ヽ\\u3000\\u3000 ﾉ \\u3000 \\u3000 │\\u3000\\u3000|\\u3000|\\u3000| \\u3000／￣|\\u3000\\u3000 |\\u3000|\\u3000| \\u3000| (￣ヽ＿_ヽ_)__) \\u3000＼二つ'}\n",
      "{'row_index': 237, 'text': \"funniest shіt to play with your family members/friends. thanks dad, you've shown the greatest FPS of all times to me\"}\n",
      "{'row_index': 332, 'text': '플레이시간이 증명해줌'}\n",
      "{'row_index': 539, 'text': '중학교 방학때 내 시간을 뺏어간 추억의 게임2'}\n",
      "{'row_index': 540, 'text': '전설의 시작 '}\n",
      "{'row_index': 637, 'text': '어렸을떄 부터 꿈꾸던 리얼한 칼싸움 게임이 구현된 게임.  이런 느낌으로 mmorpg 나왔으면 좋겠다.  컨텐츠좀 추가하면 압도적 긍정 가능할듯'}\n",
      "{'row_index': 657, 'text': '김상윤이 이 게임을 보증한다.'}\n",
      "{'row_index': 665, 'text': '\"Nalivayimo, brethren, kristalevi čaši, Aby шабli ne biši, aby kulis minaly, Golivonki naši!\" A rather bizarre mix of old good fighting with hardcore fencing [one good hit or one missed and greet] The'}\n",
      "{'row_index': 691, 'text': '그래서 뇌창은 어떻게 사용하는건데? 를 결전병기 시작 이 뭔데 ㅋㅋㅋㅋ번역 개같이 해놨네  그래서 제가 알아왔습니다   ESC - 옵션 - 조작 - 참경 장비 - 오른쪽에  보시면  결전  준비  있는데 T로 바꾸시면 됩니다.'}\n",
      "{'row_index': 923, 'text': \"我个人不认识你，但我能理解你的痛苦。 我现在是你游戏的骄傲所有者，我希望你能找到爱。  - Kacey I personally don't know you, but I can understand your pain. I am now the proud owner of your game, I hope you can find love. \\xa0- Kacey\"}\n",
      "{'row_index': 986, 'text': 'Бл*ть я тут живу'}\n",
      "{'row_index': 1074, 'text': '완성된 게임을 현대화시키는 영리한 리메이크.  물론, 현대화고 나발이고 긴건 필요할때 여전히 안나온다.'}\n",
      "{'row_index': 1135, 'text': '집중력을 높히기 위해 퍼즐게임을 구입했습니다. 엄마가 와서 나머지는 나중에 마저해야겠습니다.'}\n",
      "{'row_index': 1223, 'text': '평화로운 음악을 들으며 알리샤가 일상복, 메이드복, 도복, 네코미미, 메탈 슈트 등을 입을 수 있게 도와주면 된다. 어떻게? 퍼즐 돌려서. 참고로 도전과제 올클리어를 위해서는 Expanded Content DLC 를 구매해야 하기 때문에, 그냥 정가 1,100원이라고 생각하면 된다. 가격 싸고, 도전과제 있는 헨타이 게임에, 그 도전과제마저도 쉽다? 당연히'}\n",
      "{'row_index': 1242, 'text': '지금 하평가 받은거 별로 믿지마세요 중국에서 자기네 지도자 욕보였다고 테러중이거든요. 전반적으로 분위기가 제대로 잡혀있습니다, 서양쪽으로 치중된 공포류가 많았는데 이번에 제대로 완성도 높은 동양풍 공포가 나와서 기분이 좋네요 :) 하고 나서 현타가 오거나 분노 스탯이 쌓이긴 하지만, 이만큼 사람 심리를 뒤흔들 수 있는 게임이라는 뜻이겠네요. 음향 부분에서,'}\n",
      "{'row_index': 1246, 'text': '최근에 했던 공포게임중 가장 역대급. (어그로 아님 진심 100%)'}\n",
      "{'row_index': 1248, 'text': '짱깨빼고 다 좋아하는 게임'}\n",
      "{'row_index': 1285, 'text': '괜찮다. 양만많고 실속없는 보고서 같은 게임이 넘쳐나는 시대에..  잘 정리되고 용지 1장이라도 정성이 가득 들어간 게임이었다.  다음게임도 기대된다.'}\n",
      "{'row_index': 1447, 'text': '아직 초반이라 창작마당에 엉성한것밖에 없지만 곧 누군가 ㅈㄴ 쩌는걸 만들어줄겁니다. 두한이의 기묘한 모험 최종버전이 기대되네요  화이팅, 거울 만들기!'}\n",
      "{'row_index': 1482, 'text': '약 4~50년산의 위스키 4병과 21년산 2병이 준비돼있습니다. 자고로 위스키는 숙성될수록 맛과 향이 강해지기 때문에 야겜 소믈리에로서 평가하자면 깊은 맛과 향을 느낄 수 있었습니다. 샷으로 마시고 온더락으로 마시고 막 섞어서 폭탄주랑 칵테일도 마셔보고 입으로도 넣고 코로도 넣고 마시고 뱉고 다양하고 아낌없이 즐길 수 있습니다. 취향이 맞는 분들에게는 충분'}\n",
      "{'row_index': 1499, 'text': '전작에서 나는 알리샤의 잘빠진 모델같은 몸매를 감상할 수 있었다. 그리고 이번에 내 곁에 찾아온 소녀 니키, 그녀는 알리샤보다 살집이 조금 더 많았다. 그래서 더욱 좋았다. 알리샤에게선 찾아보기 힘들었던 니키가 가진 육덕진 몸매. 일상복, 바니걸, 기동슈트, 섹시한 메이드복··· 그 모든 모습에서 단연 돋보이는 튼실한 허벅지, 그 허벅지 사이로 내 얼굴을 '}\n",
      "{'row_index': 1507, 'text': '허미 쉬......불................ 똥이네......ㅋㅋ....!'}\n",
      "{'row_index': 1590, 'text': 'Here I will leave the cat, friends who pass by can pet it and give it a thumbs up \\u3000\\u3000\\u3000 \\u3000\\u3000／＞\\u3000\\u3000フ \\u3000\\u3000\\u3000 \\u3000\\u3000| \\u3000_\\u3000 _ l \\u3000 \\u3000\\u3000 \\u3000／` ミ＿xノ \\u3000\\u3000 \\u3000 /\\u3000\\u3000\\u3000 \\u3000 | \\u3000\\u3000\\u3000 /\\u3000 ヽ\\u3000\\u3000 ﾉ \\u3000 \\u3000 │\\u3000\\u3000|\\u3000|\\u3000| \\u3000／￣|\\u3000\\u3000 |\\u3000|\\u3000| \\u3000| (￣ヽ＿_ヽ_)__) \\u3000＼二つ'}\n",
      "{'row_index': 1719, 'text': '우라돌격과 반자이돌격의 차이를 알수있다'}\n",
      "{'row_index': 1781, 'text': '마지막 콜 오브 듀티'}\n",
      "{'row_index': 1804, 'text': '인피니티워드의 모던워페어 시리즈가 플레이어들에게 전쟁의 화려함을 연출했다면, 트레이아크의 월드앳워부터 시작하는 블랙옵스시리즈는 전쟁의 검은이면, 잔혹성, 파괴성, 광기성등을 플레이어들에게 여과없이 연출합니다. 특히 이게임같은경우 처음 일본군이나 독일군이 플레이어의 이웃과 동료들에게 저지르는 만행들을 여과없이 보여주어 복수심에 사로잡히게 하고, 그후 플레이어'}\n",
      "{'row_index': 1923, 'text': '재밌어요 근데 일정 시간 지나면 패턴이 단순하네요 세입자 감별작업 & 세입자 관리 & 집 청소 및 수리의뢰 거의 이정도라서 좀더 다양한 의뢰가 있었으면...'}\n",
      "{'row_index': 1931, 'text': '심즈느낌의 건물주가되는 갓게임입니다! 집인테리어 꾸미는 맛이 살아있고,  한글도 완벽히 잘되어있습니다! 건물주 역할을 어느정도 간접체험해볼 수 있습니다. 저도 원룸건물을 직접 관리하는 중인데, 게임에 공감되는 몇가지가 있어 반가웟습니다. 여기저기 나가는 비용, 세입자가 들어오면 요구사항도 다양하고, 세입자가 나가면 공실 홍보를 위한 도배 및 파손제품 교체는'}\n",
      "{'row_index': 1932, 'text': '더 테넌츠 번역가 김근원입니다.  드디어 출시가 되어서 기쁘네요!! 처음에는 게임이 그저 재밌어서 번역을 시작하게 되었는데, 체험판 때 많은 분들이 좋아해 주실 줄은 몰랐습니다.  많은 분들이 체험버전 때 피드백을 해주셔서 전보다 더 나은 번역을 해낼 수 있었습니다. 다시 한번 정말 감사드립니다.  제가 이 게임에 대한 정이 많은 만큼 계속 개선해나가고 싶'}\n"
     ]
    }
   ],
   "source": [
    "import csv, re, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "input_csv = Path(\"weighted_score_above_08_translated_cleaned.csv\")\n",
    "\n",
    "# 주요 비영문 스크립트 패턴 (한글, 일본어, 중국어, 키릴, 아랍, 데바나가리, 태국어)\n",
    "NON_EN_PATTERNS = [\n",
    "    re.compile(r\"[\\u3130-\\u318F\\uAC00-\\uD7AF]\"),  # Hangul\n",
    "    re.compile(r\"[\\u3040-\\u30FF]\"),               # Japanese\n",
    "    re.compile(r\"[\\u3400-\\u9FFF]\"),               # Chinese\n",
    "    re.compile(r\"[\\u0400-\\u04FF]\"),               # Cyrillic\n",
    "    re.compile(r\"[\\u0600-\\u06FF]\"),               # Arabic\n",
    "    re.compile(r\"[\\u0900-\\u097F]\"),               # Devanagari\n",
    "    re.compile(r\"[\\u0E00-\\u0E7F]\"),               # Thai\n",
    "]\n",
    "\n",
    "total, english_rows, nonenglish_rows = 0, 0, 0\n",
    "nonenglish_samples = []\n",
    "\n",
    "with open(input_csv, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for idx, row in enumerate(reader):\n",
    "        text = str(row.get(\"translated_en\") or \"\")\n",
    "        total += 1\n",
    "        # 비영문 스크립트 탐지\n",
    "        if any(p.search(text) for p in NON_EN_PATTERNS):\n",
    "            nonenglish_rows += 1\n",
    "            if len(nonenglish_samples) < 30:\n",
    "                nonenglish_samples.append({\"row_index\": idx, \"text\": text[:200]})\n",
    "        else:\n",
    "            english_rows += 1\n",
    "\n",
    "print(f\"총 행 수: {total}\")\n",
    "print(f\"영어로만 된 행: {english_rows}\")\n",
    "print(f\"비영문(번역 안 된 듯한) 행: {nonenglish_rows}\")\n",
    "print(\"\\n비영문 샘플 예시 (최대 30개):\")\n",
    "for s in nonenglish_samples:\n",
    "    print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112b36c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 행 수: 411526\n",
      "삭제된 행 수 (중국어/일본어/기타 언어): 884\n",
      "최종 행 수 (영어+한국어만 유지): 410642\n",
      "저장 완료 → weighted_score_above_08_translated_en_ko.csv\n"
     ]
    }
   ],
   "source": [
    "import csv, re\n",
    "from pathlib import Path\n",
    "\n",
    "input_csv = Path(\"weighted_score_above_08_translated_cleaned.csv\")\n",
    "output_csv = Path(\"weighted_score_above_08_translated_en_ko.csv\")\n",
    "\n",
    "# \"삭제해야 하는 언어\" 패턴만 지정 (중국어, 일본어, 키릴, 아랍, 데바나가리, 태국어)\n",
    "REMOVE_PATTERNS = [\n",
    "    re.compile(r\"[\\u3040-\\u30FF]\"),               # Japanese\n",
    "    re.compile(r\"[\\u3400-\\u9FFF]\"),               # Chinese\n",
    "    re.compile(r\"[\\u0400-\\u04FF]\"),               # Cyrillic\n",
    "    re.compile(r\"[\\u0600-\\u06FF]\"),               # Arabic\n",
    "    re.compile(r\"[\\u0900-\\u097F]\"),               # Devanagari\n",
    "    re.compile(r\"[\\u0E00-\\u0E7F]\"),               # Thai\n",
    "]\n",
    "\n",
    "def is_other_language(text: str) -> bool:\n",
    "    for p in REMOVE_PATTERNS:\n",
    "        if p.search(text):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "total, kept, dropped = 0, 0, 0\n",
    "\n",
    "with open(input_csv, \"r\", encoding=\"utf-8\", newline=\"\") as f_in, \\\n",
    "     open(output_csv, \"w\", encoding=\"utf-8-sig\", newline=\"\") as f_out:\n",
    "    \n",
    "    reader = csv.DictReader(f_in)\n",
    "    fieldnames = reader.fieldnames\n",
    "    writer = csv.DictWriter(f_out, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        total += 1\n",
    "        text = str(row.get(\"translated_en\") or \"\")\n",
    "        # 중국어/일본어/기타 언어가 있으면 DROP\n",
    "        if is_other_language(text):\n",
    "            dropped += 1\n",
    "            continue\n",
    "        kept += 1\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"총 행 수: {total}\")\n",
    "print(f\"삭제된 행 수 (중국어/일본어/기타 언어): {dropped}\")\n",
    "print(f\"최종 행 수 (영어+한국어만 유지): {kept}\")\n",
    "print(f\"저장 완료 → {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea47aff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 행 수: 410642\n",
      "영어/한국어만 포함된 행: 410642\n",
      "기타 언어가 여전히 포함된 행: 0\n",
      "\n",
      "[샘플 3000개 - 기타 언어 검출됨]\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import csv, re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "input_csv = Path(\"weighted_score_above_08_translated_en_ko.csv\")\n",
    "\n",
    "# 한국어 + 영어만 허용 → 그 외 언어 검출 패턴\n",
    "OTHER_PATTERNS = {\n",
    "    \"Japanese\": re.compile(r\"[\\u3040-\\u30FF]\"),\n",
    "    \"Chinese\": re.compile(r\"[\\u3400-\\u9FFF]\"),\n",
    "    \"Cyrillic\": re.compile(r\"[\\u0400-\\u04FF]\"),\n",
    "    \"Arabic\": re.compile(r\"[\\u0600-\\u06FF]\"),\n",
    "    \"Devanagari\": re.compile(r\"[\\u0900-\\u097F]\"),\n",
    "    \"Thai\": re.compile(r\"[\\u0E00-\\u0E7F]\"),\n",
    "}\n",
    "\n",
    "total, clean, flagged = 0, 0, 0\n",
    "flagged_samples = []\n",
    "\n",
    "with open(input_csv, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for idx, row in enumerate(reader):\n",
    "        text = str(row.get(\"translated_en\") or \"\")\n",
    "        total += 1\n",
    "        bad_langs = [name for name, pat in OTHER_PATTERNS.items() if pat.search(text)]\n",
    "        if bad_langs:\n",
    "            flagged += 1\n",
    "            if len(flagged_samples) < 3000:\n",
    "                flagged_samples.append({\n",
    "                    \"row_index\": idx,\n",
    "                    \"bad_langs\": \",\".join(bad_langs),\n",
    "                    \"preview_200\": text[:200].replace(\"\\n\",\"\\\\n\")\n",
    "                })\n",
    "        else:\n",
    "            clean += 1\n",
    "\n",
    "print(f\"총 행 수: {total}\")\n",
    "print(f\"영어/한국어만 포함된 행: {clean}\")\n",
    "print(f\"기타 언어가 여전히 포함된 행: {flagged}\")\n",
    "\n",
    "print(\"\\n[샘플 3000개 - 기타 언어 검출됨]\")\n",
    "df = pd.DataFrame(flagged_samples)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cfdd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 검사 대상 컬럼: ['translated_en', 'review']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KO→EN fixing:   0%|          | 0/410655 [45:04<?, ?it/s]\n",
      "hard-cleaning: 410642rows [00:51, 7956.67rows/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SUMMARY ===\n",
      "{'rows_before': 410642, 'rows_dropped(specials>=40 in ANY target col)': 60323, 'rows_after': 350319, 'per_column_pre_specials_ge40': {'translated_en': 0, 'review': 60323}, 'per_column_post_specials_ge40': {'translated_en': 0, 'review': 0}, 'per_column_pre_h_tokens': {'translated_en': 0, 'review': 0}, 'per_column_post_h_tokens': {'translated_en': 0, 'review': 0}, 'threshold': 40, 'checked_columns': ['translated_en', 'review'], 'output_csv': 'weighted_score_above_08_hardclean.csv'}\n",
      "\n",
      "샘플 저장: hardclean_report/violations_samples.csv\n",
      "결과 저장: weighted_score_above_08_hardclean.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === Hard-clean pipeline: remove [hN] tokens, then DROP ROWS with specials>=40 in ANY of target columns ===\n",
    "import re, csv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ----------------- 설정 -----------------\n",
    "INPUT_CSV  = \"weighted_score_above_08_translated_en_ko.csv\"   # 검사/정리할 CSV\n",
    "OUTPUT_CSV = \"weighted_score_above_08_hardclean.csv\"          # 결과 (행 단위 삭제 반영)\n",
    "REPORT_DIR = \"hardclean_report\"                                # 리포트 폴더\n",
    "CHUNK_SIZE = 50_000\n",
    "SPECIALS_THRESHOLD = 40\n",
    "# ---------------------------------------\n",
    "\n",
    "Path(REPORT_DIR).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# 1) 토큰 제거용 정규식: [h1], [ h2 ], [/h3], 전각대괄호 ［h4］, (h5) 등 변형까지 처리\n",
    "H_TOKEN = re.compile(\n",
    "    r\"[\\[\\(\\uFF3B\\u3010\\uFF08]\\s*/?\\s*h\\s*\\d+\\s*[\\]\\)\\uFF3D\\u3011\\uFF09]\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def strip_h_tokens(s: str) -> str:\n",
    "    if not s: return \"\"\n",
    "    s = s.replace(\"\\u3000\", \" \")      # 전각 공백 → 보통 공백\n",
    "    s = s.replace(\"\\u200b\", \"\")       # zero-width space 제거\n",
    "    return H_TOKEN.sub(\"\", s)\n",
    "\n",
    "def specials_count(s: str) -> int:\n",
    "    # 영숫자/공백 이외 문자의 개수\n",
    "    return sum(1 for ch in (s or \"\") if not ch.isalnum() and not ch.isspace())\n",
    "\n",
    "# 어떤 원문 컬럼이 있는지 감지\n",
    "hdr = pd.read_csv(INPUT_CSV, nrows=0).columns.tolist()\n",
    "SOURCE_COLS = [c for c in [\"review\",\"translated_src\",\"original\",\"content\",\"body\"] if c in hdr]\n",
    "TARGET_COLS = [\"translated_en\"] + SOURCE_COLS\n",
    "print(f\"[INFO] 검사 대상 컬럼: {TARGET_COLS}\")\n",
    "\n",
    "# 집계 변수\n",
    "pre_total = 0\n",
    "pre_ge40 = {c: 0 for c in TARGET_COLS}\n",
    "pre_h     = {c: 0 for c in TARGET_COLS}\n",
    "\n",
    "post_total = 0\n",
    "dropped_rows = 0\n",
    "post_ge40 = {c: 0 for c in TARGET_COLS}\n",
    "post_h     = {c: 0 for c in TARGET_COLS}\n",
    "\n",
    "# 샘플 저장(최대 1000개)\n",
    "samples_violation = []\n",
    "samples_h_tokens  = []\n",
    "\n",
    "# 출력 파일 헤더 준비(입력과 동일)\n",
    "if Path(OUTPUT_CSV).exists():\n",
    "    Path(OUTPUT_CSV).unlink()\n",
    "with open(INPUT_CSV, \"r\", encoding=\"utf-8\", newline=\"\") as fi, \\\n",
    "     open(OUTPUT_CSV, \"w\", encoding=\"utf-8-sig\", newline=\"\") as fo:\n",
    "    rdr = csv.reader(fi)\n",
    "    wtr = csv.writer(fo)\n",
    "    header = next(rdr)\n",
    "    wtr.writerow(header)\n",
    "\n",
    "# 1패스: 통계 + h토큰 제거 + 행삭제 적용하여 스트리밍 저장\n",
    "pbar = tqdm(desc=\"hard-cleaning\", unit=\"rows\")\n",
    "for chunk in pd.read_csv(INPUT_CSV, chunksize=CHUNK_SIZE, dtype=str, encoding=\"utf-8\", on_bad_lines=\"skip\"):\n",
    "    pre_total += len(chunk)\n",
    "\n",
    "    # H 토큰 제거 (대상 컬럼들만)\n",
    "    for col in TARGET_COLS:\n",
    "        if col in chunk.columns:\n",
    "            chunk[col] = chunk[col].fillna(\"\").astype(str).map(strip_h_tokens)\n",
    "\n",
    "    # pre 통계(삭제 전 기준: strip 후 specials 계산)\n",
    "    for col in TARGET_COLS:\n",
    "        if col in chunk.columns:\n",
    "            sc = chunk[col].map(specials_count)\n",
    "            pre_ge40[col] += int((sc >= SPECIALS_THRESHOLD).sum())\n",
    "            pre_h[col]    += int(chunk[col].str.contains(H_TOKEN).sum())\n",
    "\n",
    "    # 드롭 마스크: 대상 컬럼 중 하나라도 specials>=40 이면 DROP\n",
    "    drop_mask = pd.Series(False, index=chunk.index)\n",
    "    for col in TARGET_COLS:\n",
    "        if col in chunk.columns:\n",
    "            drop_mask |= chunk[col].map(lambda x: specials_count(x) >= SPECIALS_THRESHOLD)\n",
    "\n",
    "    # 샘플 수집\n",
    "    viol_idx = chunk.index[drop_mask]\n",
    "    if len(viol_idx) and len(samples_violation) < 1000:\n",
    "        take = viol_idx[:max(0, 1000 - len(samples_violation))]\n",
    "        for i in take:\n",
    "            row = {\"__row_index\": int(i)}\n",
    "            for col in TARGET_COLS:\n",
    "                if col in chunk.columns:\n",
    "                    row[f\"{col}__specials\"] = specials_count(chunk.at[i, col])\n",
    "                    row[f\"{col}__preview200\"] = (chunk.at[i, col] or \"\")[:200].replace(\"\\n\",\"\\\\n\")\n",
    "            samples_violation.append(row)\n",
    "\n",
    "    # 삭제 적용\n",
    "    kept = chunk.loc[~drop_mask].copy()\n",
    "    dropped_rows += int(drop_mask.sum())\n",
    "    post_total += len(kept)\n",
    "\n",
    "    # post 통계(남은 데이터에 대해)\n",
    "    for col in TARGET_COLS:\n",
    "        if col in kept.columns:\n",
    "            sc2 = kept[col].map(specials_count)\n",
    "            post_ge40[col] += int((sc2 >= SPECIALS_THRESHOLD).sum())\n",
    "            post_h[col]    += int(kept[col].str.contains(H_TOKEN).sum())\n",
    "\n",
    "    # append 저장\n",
    "    kept.to_csv(OUTPUT_CSV, mode=\"a\", index=False, header=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    pbar.update(len(chunk))\n",
    "pbar.close()\n",
    "\n",
    "# 리포트 생성\n",
    "summary = {\n",
    "    \"rows_before\": pre_total,\n",
    "    \"rows_dropped(specials>=40 in ANY target col)\": dropped_rows,\n",
    "    \"rows_after\": post_total,\n",
    "    \"per_column_pre_specials_ge40\": pre_ge40,\n",
    "    \"per_column_post_specials_ge40\": post_ge40,\n",
    "    \"per_column_pre_h_tokens\": pre_h,\n",
    "    \"per_column_post_h_tokens\": post_h,\n",
    "    \"threshold\": SPECIALS_THRESHOLD,\n",
    "    \"checked_columns\": TARGET_COLS,\n",
    "    \"output_csv\": OUTPUT_CSV,\n",
    "}\n",
    "pd.DataFrame([summary]).to_json(f\"{REPORT_DIR}/hardclean_summary.json\", orient=\"records\", force_ascii=False)\n",
    "pd.DataFrame(samples_violation).to_csv(f\"{REPORT_DIR}/violations_samples.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(summary)\n",
    "print(f\"\\n샘플 저장: {REPORT_DIR}/violations_samples.csv\")\n",
    "print(f\"결과 저장: {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c2ae30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0b9d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0fe59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa0e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0329c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd68ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d3f6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9673f246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39fe2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-gpu)",
   "language": "python",
   "name": "torch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
