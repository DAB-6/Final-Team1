{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuttCoqbAtKVkWFQ7zILEJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yunseokjin/Final-Team1/blob/main/1%ED%8C%80_%EC%9C%A4%EC%84%9D%EC%A7%84_%ED%8C%8C%EC%9D%B4%EB%84%90_%EB%A6%AC%EB%B7%B0%EA%B0%90%EC%84%B1%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad1uoPhc0ZEu"
      },
      "outputs": [],
      "source": [
        "#한글 글씨 폰트 설치\n",
        "%%capture\n",
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "fm.fontManager.addfont('/usr/share/fonts/truetype/nanum/NanumGothic.ttf')\n",
        "plt.rcParams['font.family'] = 'NanumGothic'\n",
        "\n",
        "# 표에서 ('-') 마이너스 표시\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================\n",
        "# [Step 1] 데이터 준비: 영어 리뷰 필터링 및 그룹핑\n",
        "# =============================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# --- 1-1. 필수 라이브러리 설치 (필요시) ---\n",
        "!pip install -q transformers torch vaderSentiment bertopic konlpy\n",
        "\n",
        "# --- 1-2. 원본 데이터 로드 ---\n",
        "file_path = '/content/S-team_250930-final.csv'\n",
        "try:\n",
        "    df_original = pd.read_csv(file_path)\n",
        "    print(f\"✅ 원본 데이터 로드 완료! (Shape: {df_original.shape})\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ 파일 로드 실패: '{file_path}' 경로를 확인해주세요.\")\n",
        "\n",
        "# --- 1-3. 언어 탐지 및 영어(비한국어) 데이터 필터링 ---\n",
        "tqdm.pandas()\n",
        "\n",
        "def detect_language(text):\n",
        "    if not isinstance(text, str) or len(text.strip()) == 0: return 'unknown'\n",
        "    return 'korean' if re.search(\"[ㄱ-힣]\", text) else 'english'\n",
        "\n",
        "# 'translated_en' 컬럼의 원본 텍스트를 기준으로 언어 탐지\n",
        "df_original['language_detected'] = df_original['review'].progress_apply(detect_language)\n",
        "\n",
        "# 🔥 분석 대상을 '영문 리뷰'로 한정\n",
        "df_english = df_original[df_original['language_detected'] != 'korean'].copy()\n",
        "print(f\"\\n✅ 영어(비한국어) 리뷰 필터링 완료! (총 {len(df_english)}개)\")\n",
        "\n",
        "\n",
        "# --- 1-4. 사용자 그룹핑 컬럼 생성 ---\n",
        "# Playtime 기준 그룹핑\n",
        "df_english['playtime_hours_at_review'] = df_english['author_playtime_at_review'] / 60.0\n",
        "# 'own'과 'trial' 그룹을 병합\n",
        "df_english['playtime_merged'] = df_english['user_groupby_playtime'].replace({\n",
        "    'own': '초기 탐색(0-10h)', 'trial': '초기 탐색(0-10h)',\n",
        "    'normal': '일반 유저', 'heavy': '헤비 유저', 'core': '코어 유저'\n",
        "})\n",
        "\n",
        "print(\"\\n--- 생성된 플레이타임 그룹 분포 ---\")\n",
        "print(df_english['playtime_merged'].value_counts())"
      ],
      "metadata": {
        "id": "2QTBJ9iH0k_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================\n",
        "# [Step 2] 감성 분석: VADER 모델 적용\n",
        "# =============================================================\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# --- 2-1. VADER 분석기 로드 ---\n",
        "vader_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# --- 2-2. 감성 점수 계산 함수 정의 ---\n",
        "def get_vader_score(text):\n",
        "    if not isinstance(text, str):\n",
        "        return 0.0\n",
        "    # VADER는 원문 텍스트에 바로 적용\n",
        "    return vader_analyzer.polarity_scores(text)['compound']\n",
        "\n",
        "# --- 2-3. 감성 점수 및 그룹 컬럼 생성 ---\n",
        "print(\"\\n영어 리뷰에 VADER 감성 분석 적용 중...\")\n",
        "df_english['sentiment_score'] = df_english['translated_en'].progress_apply(get_vader_score)\n",
        "\n",
        "def assign_sentiment_group_strict(score):\n",
        "    if score >= 0.05:\n",
        "        return 'Positive'\n",
        "    elif score <= -0.3:  # 🔥 부정 기준을 -0.05에서 -0.3으로 강화\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# 강화된 기준으로 재실행\n",
        "df_english['sentiment_group'] = df_english['sentiment_score'].apply(assign_sentiment_group_strict)\n",
        "\n",
        "print(\"\\n✅ [강화된 기준] 감성 분석 완료!\")\n",
        "print(\"--- 감성 그룹 분포 ---\")\n",
        "print(df_english['sentiment_group'].value_counts())"
      ],
      "metadata": {
        "id": "zMC8tX5W0L8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================\n",
        "# ✨ [개선된 전략] Step 3: 고도화된 LDA 토픽 모델링 ✨\n",
        "# =============================================================\n",
        "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import pandas as pd\n",
        "\n",
        "# --- 이전 Step 1 & 2는 동일하게 실행하여 'df_english' 데이터프레임을 준비합니다 ---\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✨ [개선된 분석] 그룹별 '차별화된' 주요 불만 사항 (LDA) ✨\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "playtime_categories = ['초기 탐색(0-10h)', '일반 유저', '헤비 유저', '코어 유저']\n",
        "# 그룹별 최종 결과를 저장할 딕셔너리\n",
        "final_results = {}\n",
        "\n",
        "# 🔥 [핵심 개선 1] 강력한 불용어 사전 구축\n",
        "# 기본 영어 불용어 + 일반적인 게임 용어 + 이전 분석에서 발견된 무의미한 단어 모두 추가\n",
        "custom_stop_words = list(ENGLISH_STOP_WORDS) + [\n",
        "    'game', 'games', 'play', 'playing', 'player', 'players', 'just', 'like',\n",
        "    'really', 'don', 'doesn', 'im', 've', 'time', 'lot', 'way', 'thing',\n",
        "    'good', 'bad', 'great', 'problem', 'problems', 'issue', 'issues', 'bit', 'even',\n",
        "    'got', 'didn', 'think', 'thought', 'said', 'saw', 'know', 'want', 'make',\n",
        "    'actually', 'people', 'going', 'getting', 'little', 'much', 'review', 'steam'\n",
        "]\n",
        "# 🔥 V2: 감정 표현 및 범용적 부정 단어 추가\n",
        "custom_stop_words_v2 = custom_stop_words + [\n",
        "    'kill', 'killed', 'die', 'dead', 'death', 'hate',         # 폭력/죽음 관련\n",
        "    'fuck', 'shit', 'ass', 'crap', 'motherfucking', 'bull', # 욕설/비속어\n",
        "    'bullying', 'bully',                                      # 특정 게임에서 많이 나온 불용어\n",
        "    'll', 'guy', 'guys', 'man', 'life'                         # 일반적인 명사/대명사\n",
        "]\n",
        "\n",
        "for segment in playtime_categories:\n",
        "    print(f\"\\n--- 👥 그룹: {segment} ---\")\n",
        "    segment_df = df_english[\n",
        "        (df_english['playtime_merged'] == segment) &\n",
        "        (df_english['sentiment_group'] == 'Negative') # 'Negative' 그룹만 분석\n",
        "    ]\n",
        "\n",
        "    num_docs = len(segment_df)\n",
        "    if num_docs < 50: # 분석의 신뢰도를 위해 최소 문서 수를 50으로 상향\n",
        "        print(f\"부정 리뷰 수가 {num_docs}개로 분석하기에 부족합니다.\")\n",
        "        continue\n",
        "\n",
        "    docs = segment_df['translated_en'].dropna().astype(str).tolist()\n",
        "    print(f\"총 {len(docs)}개의 영어 부정 리뷰로 LDA 토픽 모델링 시작...\")\n",
        "\n",
        "    try:\n",
        "        # 🔥 [핵심 개선 2] Vectorizer 파라미터 최적화\n",
        "        # min_df: 너무 드물게 나오는 단어 제거 (최소 10개 문서 이상 등장)\n",
        "        # max_df: 너무 자주 나오는 단어 제거 (상위 85% 이상 등장 단어 제외)\n",
        "        # ngram_range: 단어 묶음(예: 'server connection')을 함께 분석하여 의미 정확도 향상\n",
        "        vectorizer = CountVectorizer(\n",
        "            stop_words=custom_stop_words_v2,\n",
        "            min_df=10,\n",
        "            max_df=0.85,\n",
        "            ngram_range=(1, 2) # 1개 단어 및 2개 연속 단어 모두 고려\n",
        "        )\n",
        "        X = vectorizer.fit_transform(docs)\n",
        "\n",
        "        # 🔥 [핵심 개선 3] 찾고자 하는 토픽의 수를 3~5개로 줄여 명확성 확보\n",
        "        lda_model = LatentDirichletAllocation(\n",
        "            n_components=4, # 핵심 불만 4개를 찾는다고 가정\n",
        "            random_state=42,\n",
        "            learning_method='online', # 대용량 데이터에 더 빠름\n",
        "            n_jobs=-1 # 모든 CPU 코어 사용\n",
        "        )\n",
        "        lda_model.fit(X)\n",
        "\n",
        "        # 3. 결과 해석 및 저장\n",
        "        topics = []\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "        for topic_idx, topic in enumerate(lda_model.components_):\n",
        "            top_keywords = [feature_names[i] for i in topic.argsort()[:-8:-1]] # 상위 7개 키워드\n",
        "            topics.append({\n",
        "                \"Topic #\": topic_idx,\n",
        "                \"Keywords\": \", \".join(top_keywords)\n",
        "            })\n",
        "\n",
        "        results_df = pd.DataFrame(topics)\n",
        "        final_results[segment] = results_df\n",
        "        print(\"\\n🔥 발견된 주요 불만 토픽:\")\n",
        "        display(results_df)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ LDA 모델링 중 오류 발생: {e}\")"
      ],
      "metadata": {
        "id": "_Inoz7URzkVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================\n",
        "# ✨ [최종 단계] 분석 결과 요약 및 해석 ✨\n",
        "# =============================================================\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"✨ 전체 그룹별 주요 불만 사항 요약 ✨\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 이전 LDA 분석에서 도출된 키워드를 바탕으로 각 토픽에 의미(레이블)를 부여합니다.\n",
        "# 이 해석은 분석가의 주관이 들어가는 부분이며, 발표의 핵심적인 주장입니다.\n",
        "\n",
        "# --- 1. 각 그룹별 키워드 해석 및 레이블링 ---\n",
        "summary_data = {\n",
        "    '플레이타임 그룹': [\n",
        "        '초기 탐색 (0-10h)',\n",
        "        '일반 유저 (10-100h)',\n",
        "        '헤비 유저 (100h+)',\n",
        "        '코어 유저 (수백 시간+)'\n",
        "    ],\n",
        "    '핵심 불만 (Topic 1)': [\n",
        "        '기대와 다른 첫인상 (구매/가치 판단)',\n",
        "        '게임의 본질적 재미 부족 (게임플레이/스토리)',\n",
        "        '콘텐츠 고갈 및 정체 (새로운 콘텐츠/서버)',\n",
        "        '게임의 장기적 비전 부재 (소통/미래)'\n",
        "    ],\n",
        "    '대표 키워드 (Topic 1)': [\n",
        "        'buy, version, store, money, minutes',\n",
        "        'gameplay, story, characters, hard',\n",
        "        'new, enemy, server, hours',\n",
        "        'community, fun, waste, longer'\n",
        "    ],\n",
        "    '핵심 불만 (Topic 2)': [\n",
        "        '기술적 문제 및 완성도',\n",
        "        '불쾌한 경험 (난이도/전투)',\n",
        "        '반복 플레이의 피로감',\n",
        "        '커뮤니티 및 운영 문제'\n",
        "    ],\n",
        "    '대표 키워드 (Topic 2)': [\n",
        "        'chinese, old, work, wrong',\n",
        "        'gun, battle, hard, stop',\n",
        "        'team, dragon, world, died',\n",
        "        'chinese, team, mode, simulator'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# --- 2. 데이터프레임 생성 ---\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "# --- 3. 최종 요약 테이블 출력 ---\n",
        "# display() 함수는 Colab이나 Jupyter Notebook 환경에서 표를 더 예쁘게 보여줍니다.\n",
        "# 일반 Python 스크립트에서는 print(summary_df)를 사용하세요.\n",
        "display(summary_df)\n",
        "\n",
        "\n",
        "# =============================================================\n",
        "# 📖 발표용 추가 해석 및 시사점\n",
        "# =============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"📖 발표용 해석 및 시사점\")\n",
        "print(\"=\"*60)\n",
        "print(\"1. [초기 탐색 그룹]은 '구매'와 직접적으로 관련된 불만이 가장 많습니다.\")\n",
        "print(\"   -> 시사점: 스팀 스토어의 게임 설명, 스크린샷, 트레일러가 실제 게임 경험과 일치하는 것이 매우 중요합니다.\")\n",
        "print(\"\\n2. [일반 유저 그룹]은 '게임플레이', '스토리' 등 게임의 핵심 메커니즘에 대한 비판이 주를 이룹니다.\")\n",
        "print(\"   -> 시사점: 게임이 장기적으로 유저를 붙잡기 위해서는 탄탄한 기본기가 필수적입니다.\")\n",
        "print(\"\\n3. [헤비 유저 그룹]에 와서야 '서버(server)', '새로운 적(enemy)' 등 라이브 서비스 운영과 관련된 불만이 등장합니다.\")\n",
        "print(\"   -> 시사점: 안정적인 서비스와 꾸준한 콘텐츠 업데이트는 충성도 높은 유저를 유지하는 핵심입니다.\")\n",
        "print(\"\\n4. [코어 유저 그룹]은 '커뮤니티(community)', '재미의 소멸(fun, waste)' 등 게임의 지속 가능성과 방향성에 대해 이야기합니다.\")\n",
        "print(\"   -> 시사점: 이들의 목소리는 게임의 미래를 결정하는 가장 중요한 지표이며, 개발사는 이들과의 소통 채널을 반드시 확보해야 합니다.\")"
      ],
      "metadata": {
        "id": "FtugtPGx0DJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# =============================================================\n",
        "# ✨ [분석 통일성 확보] 최종 데이터셋 기반 감성 분석 및 시각화 ✨\n",
        "# =============================================================\n",
        "\n",
        "# --- 1. 이전 단계에서 생성된 'df_english' 데이터프레임을 사용합니다 ---\n",
        "# df_english 가 메모리에 없다면, 이전 코드를 실행하여 먼저 생성해주세요.\n",
        "\n",
        "print(f\"✅ 분석 대상 데이터: 영어(비한국어) 리뷰 {len(df_english)}개\")\n",
        "\n",
        "# --- 2. VADER 감성 분석 재실행 ---\n",
        "vader_analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "def get_vader_score(text):\n",
        "    if not isinstance(text, str): return 0.0\n",
        "    return vader_analyzer.polarity_scores(text)['compound']\n",
        "\n",
        "print(\"\\nVADER 감성 점수 계산 중...\")\n",
        "df_english['sentiment_score'] = df_english['translated_en'].progress_apply(get_vader_score)\n",
        "\n",
        "# 감성 그룹 분류 (기존과 동일한 기준 적용)\n",
        "def assign_sentiment_group_strict(score):\n",
        "    if score >= 0.05: return 'Positive'\n",
        "    elif score <= -0.3: return 'Negative'\n",
        "    else: return 'Neutral'\n",
        "\n",
        "df_english['sentiment_group'] = df_english['sentiment_score'].apply(assign_sentiment_group_strict)\n",
        "print(\"감성 그룹 분류 완료!\")\n",
        "print(df_english['sentiment_group'].value_counts())\n",
        "\n",
        "\n",
        "# --- 3. 감성 그룹별 추천 리뷰 비율 막대그래프 재시각화 ---\n",
        "sentiment_recommend_ratio = df_english.groupby('sentiment_group')['voted_up'].mean().reindex(['Positive', 'Neutral', 'Negative'])\n",
        "\n",
        "print(\"\\n--- [최종 데이터셋 기준] 감성 그룹별 추천(voted_up=1) 비율 ---\")\n",
        "print(sentiment_recommend_ratio)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=sentiment_recommend_ratio.index, y=sentiment_recommend_ratio.values, palette='viridis')\n",
        "plt.title('[최종 분석 데이터 기준] 감성 그룹별 추천 리뷰 비율', fontsize=16, pad=20)\n",
        "plt.ylabel('추천 비율 (voted_up의 평균)', fontsize=12)\n",
        "plt.xlabel('리뷰 텍스트의 감성 그룹', fontsize=12)\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# 막대 위에 비율 텍스트 표시\n",
        "for i, val in enumerate(sentiment_recommend_ratio):\n",
        "    plt.text(i, val + 0.02, f'{val:.2%}', ha='center', fontsize=12)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZZ3k8LZ_0XMS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}